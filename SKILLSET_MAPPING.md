# AI Engineering Skillset Mapping

A structured view of capabilities across the AI Engineering landscape, showing existing strengths, active learning, and planned development.

---

## How to Read This Map

- âœ… **Proficient**: Currently strong, applied in practice
- ðŸ”„ **Developing**: Actively learning, hands-on experience building
- ðŸ“‹ **Planned**: Upcoming in curriculum or identified for future learning
- ðŸ”— **Transferable**: Existing skill from UX/Strategy background that applies directly

---

## Core Competency Domains

### 1. Product & Strategy

#### Product Thinking & Vision
- âœ… Product strategy and roadmapping
- âœ… User-centered design methodology
- âœ… Cross-functional team collaboration
- âœ… Translating between business and technical domains
- ðŸ”— Understanding product-market fit beyond technical metrics
- ðŸ”— Identifying usability gaps in AI implementations

#### User Experience & Interaction Design
- âœ… User research and testing (moderated/unmoderated)
- âœ… Information architecture
- âœ… Conversational design principles
- âœ… Design systems thinking
- âœ… Accessibility (WCAG 2.1)
- ðŸ”— Designing for AI-human interaction patterns
- ðŸ”„ Prompt UX and conversation flow design

#### Content & Communication
- âœ… Content strategy
- âœ… Linguistics and taxonomy development
- âœ… Localization and international UX
- ðŸ”— Prompt engineering as applied linguistics
- ðŸ”„ Model behavior through language design

---

### 2. AI/ML Fundamentals

#### Language Models & Architecture
- ðŸ”„ LLM capabilities and limitations
- ðŸ”„ Model selection and evaluation
- ðŸ”„ Token economics and context windows
- ðŸ”„ Temperature, top-p, and sampling parameters
- ðŸ“‹ Model fine-tuning techniques
- ðŸ“‹ Embeddings and vector representations

#### Prompt Engineering
- ðŸ”„ Instruction design and optimization
- ðŸ”„ Few-shot and zero-shot learning
- ðŸ”„ Chain-of-thought prompting
- ðŸ”„ Prompt iteration and testing
- ðŸ”„ System prompts and role definition
- ðŸ”— Applying UX testing methods to prompt validation

#### Classification & Model Behavior
- ðŸ”„ Understanding model classification approaches
- ðŸ”„ Output formatting and structuring
- ðŸ”„ Handling model inconsistency and reliability
- ðŸ“‹ Model evaluation metrics

---

### 3. Application Development

#### RAG (Retrieval Augmented Generation)
- ðŸ”„ RAG architecture and use cases
- ðŸ”„ Document chunking strategies
- ðŸ“‹ Vector database integration
- ðŸ“‹ Retrieval optimization
- ðŸ“‹ Hybrid search approaches

#### AI Agents & Orchestration
- ðŸ“‹ Agent architecture patterns
- ðŸ“‹ Tool/function calling
- ðŸ“‹ Multi-agent systems
- ðŸ“‹ LangChain/LangGraph frameworks
- ðŸ”— Service design thinking for agent workflows

#### API Integration
- ðŸ”„ LLM API usage (OpenAI, Anthropic, etc.)
- ðŸ”„ Request/response handling
- ðŸ”„ Error handling and fallbacks
- ðŸ“‹ Rate limiting and optimization
- ðŸ“‹ Streaming responses

---

### 4. Technical Implementation

#### Development Tools & Workflows
- âœ… Git/version control
- âœ… VS Code and development environments
- ðŸ”„ Cursor AI and AI-assisted coding
- ðŸ”„ Jupyter Notebooks for experimentation
- ðŸ“‹ Docker and containerization
- ðŸ“‹ CI/CD pipelines

#### Programming & Scripting
- âœ… HTML/CSS (hand-coded)
- ðŸ”„ Python fundamentals
- ðŸ”„ Working with APIs and libraries
- ðŸ“‹ Async programming patterns
- ðŸ“‹ Error handling and debugging
- ðŸ”— Applying systematic testing approaches from UX

#### Data Handling
- ðŸ”„ JSON/structured data manipulation
- ðŸ”„ File I/O and data processing
- ðŸ“‹ Database basics
- ðŸ“‹ Vector databases (Pinecone, Weaviate, etc.)
- ðŸ“‹ Data pipeline design

---

### 5. Frameworks & Tools

#### LLM Application Frameworks
- ðŸ“‹ LangChain (chains, agents, memory)
- ðŸ“‹ LangGraph (stateful workflows)
- ðŸ“‹ Other orchestration frameworks

#### Vector & Database Systems
- ðŸ“‹ Pinecone
- ðŸ“‹ Weaviate
- ðŸ“‹ Chroma
- ðŸ“‹ Traditional databases (Postgres, etc.)

#### Development & Prototyping
- âœ… Figma, Miro, Mural (design/collaboration)
- ðŸ”„ V0, Cursor (AI-assisted prototyping)
- ðŸ”„ ChatGPT, Claude (experimentation)
- ðŸ“‹ Streamlit or Gradio (app interfaces)

---

### 6. Deployment & Production

#### Model Operations
- ðŸ“‹ Model deployment strategies
- ðŸ“‹ Monitoring and logging
- ðŸ“‹ Cost optimization
- ðŸ“‹ Performance tuning
- ðŸ”— Applying usability testing to model behavior in production

#### Infrastructure (Awareness Level)
- ðŸ“‹ Cloud platforms (AWS, Azure, GCP)
- ðŸ“‹ Serverless functions
- ðŸ“‹ API gateway patterns
- ðŸ“‹ Security and privacy considerations

---

## Unique Value Proposition

### Where UX/Strategy Background Creates Advantage

**Product Sense Over Pure Technical Execution**
- Can identify when teams fixate on speed/debugging without vision
- Understand that model performance means nothing without usability
- Bridge between "it works technically" and "it works for users"

**Human-Centered AI Development**
- Apply user research methods to model behavior testing
- Design conversation flows that feel natural, not robotic
- Consider accessibility, localization, edge cases from the start

**Strategic Thinking**
- Connect AI capabilities to business value
- Roadmap AI features within product strategy
- Understand when AI is (and isn't) the right solution

**Cross-Functional Translation**
- Communicate between data scientists, engineers, and business stakeholders
- Facilitate alignment around user needs vs technical possibilities
- Document and systematize patterns others miss

---

## Learning Trajectory

### Current Phase (November 2025)
**Bootcamp Focus**: Generative AI, LLM Apps, AI Agents

**Active Work**:
- Prompt engineering fundamentals and optimization
- LLM API integration and application patterns
- RAG system concepts and architecture
- Beginning LangChain/agent frameworks

### Next 2-3 Months
- Deep dive into vector databases and retrieval
- Agent architecture and multi-agent systems
- Fine-tuning and model customization
- Production deployment patterns

### 6-12 Month Horizon
- Advanced agent orchestration
- Model evaluation and monitoring
- Scaling and optimization
- Contributing to open source AI tools
- Building production-grade applications

---

## Open Questions & Areas of Exploration

**Role Definition**
- Where does "AI Engineer" end and "ML Engineer" begin?
- How much infrastructure knowledge is essential vs. nice-to-have?
- What distinguishes AI Engineering from AI Product Management?

**Skill Gaps to Address**
- Depth in Python (async, testing, advanced patterns)
- Infrastructure and deployment (Docker, cloud platforms)
- Database design and optimization
- Model fine-tuning hands-on experience

**Emerging Areas**
- Synthetic data generation
- Model safety and alignment
- Multi-modal AI applications
- AI agent marketplaces and platforms

---

## Notes

This map is **intentionally dynamic**. AI Engineering as a discipline is still forming, and skillsets are evolving rapidly. The goal isn't to have everything locked down, but to:

1. Provide clarity on current capabilities
2. Show active learning and progression
3. Demonstrate strategic thinking about skill development
4. Make it easy for collaborators to see where I am and where I'm going

The absence of something from this map doesn't necessarily indicate a gap - it may simply be emerging, undefined, or not yet relevant to my particular path in AI Engineering.

---

*Last Updated: November 2025*
